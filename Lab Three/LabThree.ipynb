{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation and Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buisness Use Case\n",
    "\n",
    "TODO: Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or used mostly for offline analysis? As in previous labs, also detail how good the classifier needs to perform in order to be useful. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed:  513\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zpid</th>\n",
       "      <th>city</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>propertyTaxRate</th>\n",
       "      <th>garageSpaces</th>\n",
       "      <th>hasAssociation</th>\n",
       "      <th>hasCooling</th>\n",
       "      <th>hasGarage</th>\n",
       "      <th>...</th>\n",
       "      <th>numOfElementarySchools</th>\n",
       "      <th>numOfMiddleSchools</th>\n",
       "      <th>numOfHighSchools</th>\n",
       "      <th>avgSchoolDistance</th>\n",
       "      <th>avgSchoolRating</th>\n",
       "      <th>avgSchoolSize</th>\n",
       "      <th>MedianStudentsPerTeacher</th>\n",
       "      <th>numOfBathrooms</th>\n",
       "      <th>numOfBedrooms</th>\n",
       "      <th>numOfStories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111373431</td>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.430632</td>\n",
       "      <td>-97.663078</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1063</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120900430</td>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.432673</td>\n",
       "      <td>-97.661697</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1063</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2084491383</td>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.409748</td>\n",
       "      <td>-97.639771</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1108</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120901374</td>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.432112</td>\n",
       "      <td>-97.661659</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1063</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60134862</td>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.437368</td>\n",
       "      <td>-97.656860</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1223</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         zpid          city  zipcode   latitude  longitude  propertyTaxRate  \\\n",
       "0   111373431  pflugerville    78660  30.430632 -97.663078             1.98   \n",
       "1   120900430  pflugerville    78660  30.432673 -97.661697             1.98   \n",
       "2  2084491383  pflugerville    78660  30.409748 -97.639771             1.98   \n",
       "3   120901374  pflugerville    78660  30.432112 -97.661659             1.98   \n",
       "4    60134862  pflugerville    78660  30.437368 -97.656860             1.98   \n",
       "\n",
       "   garageSpaces  hasAssociation  hasCooling  hasGarage  ...  \\\n",
       "0             2            True        True       True  ...   \n",
       "1             2            True        True       True  ...   \n",
       "2             0            True        True      False  ...   \n",
       "3             2            True        True       True  ...   \n",
       "4             0            True        True      False  ...   \n",
       "\n",
       "   numOfElementarySchools  numOfMiddleSchools  numOfHighSchools  \\\n",
       "0                       0                   1                 1   \n",
       "1                       0                   1                 1   \n",
       "2                       2                   1                 1   \n",
       "3                       0                   1                 1   \n",
       "4                       0                   1                 1   \n",
       "\n",
       "  avgSchoolDistance  avgSchoolRating  avgSchoolSize MedianStudentsPerTeacher  \\\n",
       "0          1.266667         2.666667           1063                       14   \n",
       "1          1.400000         2.666667           1063                       14   \n",
       "2          1.200000         3.000000           1108                       14   \n",
       "3          1.400000         2.666667           1063                       14   \n",
       "4          1.133333         4.000000           1223                       14   \n",
       "\n",
       "  numOfBathrooms  numOfBedrooms  numOfStories  \n",
       "0            3.0              4             2  \n",
       "1            2.0              4             1  \n",
       "2            2.0              3             1  \n",
       "3            2.0              3             1  \n",
       "4            3.0              3             2  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('austinHousingData.csv')\n",
    "\n",
    "#\n",
    "# Update columns\n",
    "#\n",
    "\n",
    "# Drop Street Address, description, homeImage\n",
    "data = data.drop(['streetAddress', 'description', 'homeImage', 'numOfPhotos', 'latestPriceSource', 'numPriceChanges'], axis=1)\n",
    "\n",
    "# Remove extreme outliers\n",
    "third_quartile = data['latestPrice'].quantile(0.75)\n",
    "first_quartile = data['latestPrice'].quantile(0.25)\n",
    "IQR = third_quartile - first_quartile\n",
    "\n",
    "initial_count = data.shape[0]\n",
    "data = data[data['latestPrice'] < (third_quartile + 3 * IQR)]\n",
    "data = data[data['latestPrice'] > (first_quartile - 3 * IQR)]\n",
    "print(\"Number of outliers removed: \", initial_count - data.shape[0])\n",
    "\n",
    "# Set the latestPrice to a categorical variable\n",
    "data['latestPrice'] = pd.cut(data['latestPrice'], \n",
    "                             bins=[0, \n",
    "                                   data['latestPrice'].quantile(0.33), \n",
    "                                   data['latestPrice'].quantile(0.66), \n",
    "                                   data['latestPrice'].max()], \n",
    "                             labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "#\n",
    "# Display Data information\n",
    "#\n",
    "\n",
    "# Print the first 5 rows of the dataframe.\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add a description of the data preprocessing steps and explain decisions made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy similar code from Lab 1 to display: data types/description, missing values, duplicate rows, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zpid</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>propertyTaxRate</th>\n",
       "      <th>garageSpaces</th>\n",
       "      <th>parkingSpaces</th>\n",
       "      <th>yearBuilt</th>\n",
       "      <th>latest_salemonth</th>\n",
       "      <th>latest_saleyear</th>\n",
       "      <th>...</th>\n",
       "      <th>numOfElementarySchools</th>\n",
       "      <th>numOfMiddleSchools</th>\n",
       "      <th>numOfHighSchools</th>\n",
       "      <th>avgSchoolDistance</th>\n",
       "      <th>avgSchoolRating</th>\n",
       "      <th>avgSchoolSize</th>\n",
       "      <th>MedianStudentsPerTeacher</th>\n",
       "      <th>numOfBathrooms</th>\n",
       "      <th>numOfBedrooms</th>\n",
       "      <th>numOfStories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.465800e+04</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.043356e+08</td>\n",
       "      <td>78736.360076</td>\n",
       "      <td>30.291285</td>\n",
       "      <td>-97.777458</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>1.201392</td>\n",
       "      <td>1.196753</td>\n",
       "      <td>1988.247101</td>\n",
       "      <td>6.719607</td>\n",
       "      <td>2019.073407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044344</td>\n",
       "      <td>1.032678</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>1.824960</td>\n",
       "      <td>5.740649</td>\n",
       "      <td>1234.836062</td>\n",
       "      <td>14.836540</td>\n",
       "      <td>2.605025</td>\n",
       "      <td>3.407150</td>\n",
       "      <td>1.453882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.173372e+08</td>\n",
       "      <td>18.813433</td>\n",
       "      <td>0.098254</td>\n",
       "      <td>0.085342</td>\n",
       "      <td>0.053957</td>\n",
       "      <td>1.318840</td>\n",
       "      <td>1.319437</td>\n",
       "      <td>21.428899</td>\n",
       "      <td>3.143685</td>\n",
       "      <td>0.813386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226084</td>\n",
       "      <td>0.249629</td>\n",
       "      <td>0.285393</td>\n",
       "      <td>1.046277</td>\n",
       "      <td>1.862691</td>\n",
       "      <td>329.232708</td>\n",
       "      <td>1.755436</td>\n",
       "      <td>0.940756</td>\n",
       "      <td>0.826083</td>\n",
       "      <td>0.518033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.858495e+07</td>\n",
       "      <td>78617.000000</td>\n",
       "      <td>30.085030</td>\n",
       "      <td>-98.022057</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1906.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.941403e+07</td>\n",
       "      <td>78727.000000</td>\n",
       "      <td>30.201381</td>\n",
       "      <td>-97.836798</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1974.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>966.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.949565e+07</td>\n",
       "      <td>78739.000000</td>\n",
       "      <td>30.282641</td>\n",
       "      <td>-97.768124</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1277.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.033766e+07</td>\n",
       "      <td>78749.000000</td>\n",
       "      <td>30.368274</td>\n",
       "      <td>-97.715643</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1496.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.146313e+09</td>\n",
       "      <td>78759.000000</td>\n",
       "      <td>30.517323</td>\n",
       "      <td>-97.569504</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>1913.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               zpid       zipcode      latitude     longitude  \\\n",
       "count  1.465800e+04  14658.000000  14658.000000  14658.000000   \n",
       "mean   1.043356e+08  78736.360076     30.291285    -97.777458   \n",
       "std    3.173372e+08     18.813433      0.098254      0.085342   \n",
       "min    2.858495e+07  78617.000000     30.085030    -98.022057   \n",
       "25%    2.941403e+07  78727.000000     30.201381    -97.836798   \n",
       "50%    2.949565e+07  78739.000000     30.282641    -97.768124   \n",
       "75%    7.033766e+07  78749.000000     30.368274    -97.715643   \n",
       "max    2.146313e+09  78759.000000     30.517323    -97.569504   \n",
       "\n",
       "       propertyTaxRate  garageSpaces  parkingSpaces     yearBuilt  \\\n",
       "count     14658.000000  14658.000000   14658.000000  14658.000000   \n",
       "mean          1.994561      1.201392       1.196753   1988.247101   \n",
       "std           0.053957      1.318840       1.319437     21.428899   \n",
       "min           1.980000      0.000000       0.000000   1906.000000   \n",
       "25%           1.980000      0.000000       0.000000   1974.000000   \n",
       "50%           1.980000      1.000000       1.000000   1992.000000   \n",
       "75%           1.980000      2.000000       2.000000   2006.000000   \n",
       "max           2.210000     22.000000      22.000000   2020.000000   \n",
       "\n",
       "       latest_salemonth  latest_saleyear  ...  numOfElementarySchools  \\\n",
       "count      14658.000000     14658.000000  ...            14658.000000   \n",
       "mean           6.719607      2019.073407  ...                0.044344   \n",
       "std            3.143685         0.813386  ...                0.226084   \n",
       "min            1.000000      2018.000000  ...                0.000000   \n",
       "25%            4.000000      2018.000000  ...                0.000000   \n",
       "50%            7.000000      2019.000000  ...                0.000000   \n",
       "75%            9.000000      2020.000000  ...                0.000000   \n",
       "max           12.000000      2021.000000  ...                2.000000   \n",
       "\n",
       "       numOfMiddleSchools  numOfHighSchools  avgSchoolDistance  \\\n",
       "count        14658.000000      14658.000000       14658.000000   \n",
       "mean             1.032678          0.983081           1.824960   \n",
       "std              0.249629          0.285393           1.046277   \n",
       "min              0.000000          0.000000           0.200000   \n",
       "25%              1.000000          1.000000           1.100000   \n",
       "50%              1.000000          1.000000           1.566667   \n",
       "75%              1.000000          1.000000           2.266667   \n",
       "max              3.000000          2.000000           9.000000   \n",
       "\n",
       "       avgSchoolRating  avgSchoolSize  MedianStudentsPerTeacher  \\\n",
       "count     14658.000000   14658.000000              14658.000000   \n",
       "mean          5.740649    1234.836062                 14.836540   \n",
       "std           1.862691     329.232708                  1.755436   \n",
       "min           2.333333     396.000000                 10.000000   \n",
       "25%           4.000000     966.000000                 14.000000   \n",
       "50%           5.666667    1277.000000                 15.000000   \n",
       "75%           7.000000    1496.000000                 16.000000   \n",
       "max           9.500000    1913.000000                 19.000000   \n",
       "\n",
       "       numOfBathrooms  numOfBedrooms  numOfStories  \n",
       "count    14658.000000   14658.000000  14658.000000  \n",
       "mean         2.605025       3.407150      1.453882  \n",
       "std          0.940756       0.826083      0.518033  \n",
       "min          0.000000       0.000000      1.000000  \n",
       "25%          2.000000       3.000000      1.000000  \n",
       "50%          3.000000       3.000000      1.000000  \n",
       "75%          3.000000       4.000000      2.000000  \n",
       "max         27.000000      20.000000      4.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable Breakdown\n",
    "data.describe() # TODO: We could probably make this more relevant to the data by only showing the relevant columns (i.e. not the ID columns, binary columns should be shown as counts, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Determine if we need to do any further discussion of the data descriptions here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Argue \"for\" or \"against\" splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (5 points total)\n",
    "The implementation of logistic regression must be written only from the examples given to you by the instructor. No credit will be assigned to teams that copy implementations from another source, regardless of if the code is properly cited. \n",
    "[2 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template developed by the instructor in the course. You should add the following functionality to the logistic regression classifier:\n",
    "Ability to choose optimization technique when class is instantiated: either steepest ascent, stochastic gradient ascent, and Newton's method. It is recommended to call this the \"solver\" input for the class.\n",
    "Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1 and L2 regularization). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  \n",
    "[1.5 points] Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term(s) \"C\" to achieve the best performance on your test set. Visualize the performance of the classifier versus the parameters you investigated.\n",
    "Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?\n",
    "[1.5 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time and classification performance. Discuss the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Binary Logistic Regression Object, Not Trainable\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_intercept(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, add_intercept=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_intercept(X) if add_intercept else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained Binary Logistic Regression Object\n"
     ]
    }
   ],
   "source": [
    "# inherit from base class\n",
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    #private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape) # set gradient to zero\n",
    "        for (xi,yi) in zip(X,y):\n",
    "            # the actual update inside of sum\n",
    "            gradi = (yi - self.predict_proba(xi,add_intercept=False))*xi \n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape) \n",
    "        \n",
    "        return gradient/float(len(y))\n",
    "       \n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_intercept(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets do some vectorized coding\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_intercept=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        return gradient.reshape(self.w_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained MultiClass Logistic Regression Object\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[-6.90365854e+00 -5.04963980e+06 -5.43771842e+05 -2.08402749e+02\n",
      "   6.73519711e+02 -1.40112929e+01  4.60777332e+00  4.52787396e+00\n",
      "  -1.37086729e+04 -3.75071678e+01 -1.39352558e+04  2.45569674e-01\n",
      "  -1.88609159e+01 -7.06876599e+00  2.49570186e+00  2.04191540e+00\n",
      "   6.20501450e-02  2.18264540e+00  8.54255501e-02 -1.28256844e+05\n",
      "   1.70405213e+04 -9.00285690e+00  1.61067286e+00 -5.19011598e+00\n",
      "  -1.06327222e+01 -8.93176620e+00  1.64395892e+01 -5.49352600e+03\n",
      "  -6.15405296e+01  9.02877793e+00 -6.90583746e+00 -2.43951049e+00]\n",
      " [ 4.53525499e+00 -5.26920120e+06  3.57188362e+05  1.36561618e+02\n",
      "  -4.41491562e+02  8.99404460e+00 -5.79250810e+00 -5.65857496e+00\n",
      "   9.07646158e+03  1.92359756e+01  9.15076019e+03 -2.25972199e-01\n",
      "   9.48799250e+00  2.65162459e+00 -7.22407471e+00 -3.98856388e+00\n",
      "  -4.96332935e-02 -3.05477571e+00 -1.88222753e-01  3.90070416e+05\n",
      "  -1.59219417e+04  5.93934846e+00 -6.14348456e-01  3.30845130e+00\n",
      "   9.26488146e+00  8.17774116e+00 -3.30160253e+01  3.13815748e+03\n",
      "   2.14460472e+01 -6.70286969e+00  1.93892632e+00  1.46755074e+00]\n",
      " [ 2.21832680e+00 -5.57771975e+06  1.74766982e+05  6.72951682e+01\n",
      "  -2.17353955e+02  4.71790449e+00  1.00467764e+00  9.51334641e-01\n",
      "   4.33381473e+03  1.72618497e+01  4.48147932e+03 -2.15546648e-02\n",
      "   8.85289101e+00  4.16175593e+00  4.62975439e+00  1.87650520e+00\n",
      "  -1.26215248e-02  8.40388879e-01  9.99061914e-02 -2.63872489e+05\n",
      "  -1.43838537e+03  2.92155040e+00 -1.00279294e+00  1.72668429e+00\n",
      "   1.22016033e+00  4.80060741e-01  1.57136657e+01  2.17007491e+03\n",
      "   3.78674356e+01 -2.71783217e+00  4.45528313e+00  7.53249190e-01]]\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,\n",
    "                                                 self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row\n",
    "    \n",
    "lr = LogisticRegression(0.1,1500)\n",
    "\n",
    "# Set X to all columns except for the latestPrice and non-numeric columns\n",
    "X = train.drop('latestPrice', axis=1)\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "y = train['latestPrice']\n",
    "\n",
    "lr.fit(X.values,y.values)\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High' 'High' 'High' ... 'High' 'High' 'High']\n",
      "Accuracy of:  0.3393587994542974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Now we can predict the test set\n",
    "X_test = test.drop('latestPrice', axis=1)\n",
    "X_test = X_test.select_dtypes(include=[np.number])\n",
    "\n",
    "y_test = test['latestPrice']\n",
    "\n",
    "yhat = lr.predict(X_test.values)\n",
    "\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment (1 points total)\n",
    "Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party implementation)? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work (1 points total)\n",
    "You have free reign to provide additional analyses. One idea: Update the code to use either \"one-versus-all\" or \"one-versus-one\" extensions of binary to multi-class classification. \n",
    "Required for 7000 level students: Implement an optimization technique for logistic regression using mean square error as your objective function (instead of maximum likelihood). Derive the gradient updates for the Hessian and use Newton's method to update the values of \"w\". Then answer, which process do you prefer: maximum likelihood OR minimum mean-squared error? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
