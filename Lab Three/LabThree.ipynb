{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation and Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buisness Use Case\n",
    "\n",
    "TODO: Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or used mostly for offline analysis? As in previous labs, also detail how good the classifier needs to perform in order to be useful. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed:  513\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>propertyTaxRate</th>\n",
       "      <th>hasAssociation</th>\n",
       "      <th>hasCooling</th>\n",
       "      <th>hasGarage</th>\n",
       "      <th>hasHeating</th>\n",
       "      <th>hasSpa</th>\n",
       "      <th>...</th>\n",
       "      <th>numOfElementarySchools</th>\n",
       "      <th>numOfMiddleSchools</th>\n",
       "      <th>numOfHighSchools</th>\n",
       "      <th>avgSchoolDistance</th>\n",
       "      <th>avgSchoolRating</th>\n",
       "      <th>avgSchoolSize</th>\n",
       "      <th>MedianStudentsPerTeacher</th>\n",
       "      <th>numOfBathrooms</th>\n",
       "      <th>numOfBedrooms</th>\n",
       "      <th>numOfStories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.430632</td>\n",
       "      <td>-97.663078</td>\n",
       "      <td>1.98</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1063</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.432673</td>\n",
       "      <td>-97.661697</td>\n",
       "      <td>1.98</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1063</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.409748</td>\n",
       "      <td>-97.639771</td>\n",
       "      <td>1.98</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1108</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.432112</td>\n",
       "      <td>-97.661659</td>\n",
       "      <td>1.98</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1063</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pflugerville</td>\n",
       "      <td>78660</td>\n",
       "      <td>30.437368</td>\n",
       "      <td>-97.656860</td>\n",
       "      <td>1.98</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1223</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city  zipcode   latitude  longitude  propertyTaxRate  \\\n",
       "0  pflugerville    78660  30.430632 -97.663078             1.98   \n",
       "1  pflugerville    78660  30.432673 -97.661697             1.98   \n",
       "2  pflugerville    78660  30.409748 -97.639771             1.98   \n",
       "3  pflugerville    78660  30.432112 -97.661659             1.98   \n",
       "4  pflugerville    78660  30.437368 -97.656860             1.98   \n",
       "\n",
       "   hasAssociation  hasCooling  hasGarage  hasHeating  hasSpa  ...  \\\n",
       "0            True        True       True        True   False  ...   \n",
       "1            True        True       True        True   False  ...   \n",
       "2            True        True      False        True   False  ...   \n",
       "3            True        True       True        True   False  ...   \n",
       "4            True        True      False        True   False  ...   \n",
       "\n",
       "   numOfElementarySchools numOfMiddleSchools  numOfHighSchools  \\\n",
       "0                       0                  1                 1   \n",
       "1                       0                  1                 1   \n",
       "2                       2                  1                 1   \n",
       "3                       0                  1                 1   \n",
       "4                       0                  1                 1   \n",
       "\n",
       "   avgSchoolDistance avgSchoolRating avgSchoolSize  MedianStudentsPerTeacher  \\\n",
       "0           1.266667        2.666667          1063                        14   \n",
       "1           1.400000        2.666667          1063                        14   \n",
       "2           1.200000        3.000000          1108                        14   \n",
       "3           1.400000        2.666667          1063                        14   \n",
       "4           1.133333        4.000000          1223                        14   \n",
       "\n",
       "   numOfBathrooms  numOfBedrooms  numOfStories  \n",
       "0             3.0              4             2  \n",
       "1             2.0              4             1  \n",
       "2             2.0              3             1  \n",
       "3             2.0              3             1  \n",
       "4             3.0              3             2  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('austinHousingData.csv')\n",
    "\n",
    "#\n",
    "# Update columns\n",
    "#\n",
    "\n",
    "# Drop Street Address, description, homeImage\n",
    "data = data.drop(['zpid', 'garageSpaces', 'streetAddress', 'description', 'homeImage', 'numOfPhotos', 'latestPriceSource', 'numPriceChanges'], axis=1)\n",
    "\n",
    "# Remove extreme outliers\n",
    "third_quartile = data['latestPrice'].quantile(0.75)\n",
    "first_quartile = data['latestPrice'].quantile(0.25)\n",
    "IQR = third_quartile - first_quartile\n",
    "\n",
    "initial_count = data.shape[0]\n",
    "data = data[data['latestPrice'] < (third_quartile + 3 * IQR)]\n",
    "data = data[data['latestPrice'] > (first_quartile - 3 * IQR)]\n",
    "print(\"Number of outliers removed: \", initial_count - data.shape[0])\n",
    "\n",
    "# Set the latestPrice to a categorical variable\n",
    "data['latestPrice'] = pd.cut(data['latestPrice'], \n",
    "                             bins=[0, \n",
    "                                   data['latestPrice'].quantile(0.33), \n",
    "                                   data['latestPrice'].quantile(0.66), \n",
    "                                   data['latestPrice'].max()], \n",
    "                             labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "#\n",
    "# Display Data information\n",
    "#\n",
    "\n",
    "# Print the first 5 rows of the dataframe.\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add a description of the data preprocessing steps and explain decisions made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy similar code from Lab 1 to display: data types/description, missing values, duplicate rows, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city                            object\n",
      "zipcode                          int64\n",
      "latitude                       float64\n",
      "longitude                      float64\n",
      "propertyTaxRate                float64\n",
      "hasAssociation                    bool\n",
      "hasCooling                        bool\n",
      "hasGarage                         bool\n",
      "hasHeating                        bool\n",
      "hasSpa                            bool\n",
      "hasView                           bool\n",
      "homeType                        object\n",
      "parkingSpaces                    int64\n",
      "yearBuilt                        int64\n",
      "latestPrice                   category\n",
      "latest_saledate                 object\n",
      "latest_salemonth                 int64\n",
      "latest_saleyear                  int64\n",
      "numOfAccessibilityFeatures       int64\n",
      "numOfAppliances                  int64\n",
      "numOfParkingFeatures             int64\n",
      "numOfPatioAndPorchFeatures       int64\n",
      "numOfSecurityFeatures            int64\n",
      "numOfWaterfrontFeatures          int64\n",
      "numOfWindowFeatures              int64\n",
      "numOfCommunityFeatures           int64\n",
      "lotSizeSqFt                    float64\n",
      "livingAreaSqFt                 float64\n",
      "numOfPrimarySchools              int64\n",
      "numOfElementarySchools           int64\n",
      "numOfMiddleSchools               int64\n",
      "numOfHighSchools                 int64\n",
      "avgSchoolDistance              float64\n",
      "avgSchoolRating                float64\n",
      "avgSchoolSize                    int64\n",
      "MedianStudentsPerTeacher         int64\n",
      "numOfBathrooms                 float64\n",
      "numOfBedrooms                    int64\n",
      "numOfStories                     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# data types\n",
    "print(data.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a list of the data we are working with. We will be using a mix of bool, int, float, and string data types. The variable names are self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city                          0\n",
      "zipcode                       0\n",
      "latitude                      0\n",
      "longitude                     0\n",
      "propertyTaxRate               0\n",
      "hasAssociation                0\n",
      "hasCooling                    0\n",
      "hasGarage                     0\n",
      "hasHeating                    0\n",
      "hasSpa                        0\n",
      "hasView                       0\n",
      "homeType                      0\n",
      "parkingSpaces                 0\n",
      "yearBuilt                     0\n",
      "latestPrice                   0\n",
      "latest_saledate               0\n",
      "latest_salemonth              0\n",
      "latest_saleyear               0\n",
      "numOfAccessibilityFeatures    0\n",
      "numOfAppliances               0\n",
      "numOfParkingFeatures          0\n",
      "numOfPatioAndPorchFeatures    0\n",
      "numOfSecurityFeatures         0\n",
      "numOfWaterfrontFeatures       0\n",
      "numOfWindowFeatures           0\n",
      "numOfCommunityFeatures        0\n",
      "lotSizeSqFt                   0\n",
      "livingAreaSqFt                0\n",
      "numOfPrimarySchools           0\n",
      "numOfElementarySchools        0\n",
      "numOfMiddleSchools            0\n",
      "numOfHighSchools              0\n",
      "avgSchoolDistance             0\n",
      "avgSchoolRating               0\n",
      "avgSchoolSize                 0\n",
      "MedianStudentsPerTeacher      0\n",
      "numOfBathrooms                0\n",
      "numOfBedrooms                 0\n",
      "numOfStories                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing Values\n",
    "\n",
    "# Show the number of missing values in each column\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Show the number of duplicated rows\n",
    "print(data.duplicated().sum())\n",
    "\n",
    "# Show as a percentage the number of duplicated rows\n",
    "print((data.duplicated().sum() / data.shape[0] * 100).round(3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>propertyTaxRate</th>\n",
       "      <th>parkingSpaces</th>\n",
       "      <th>yearBuilt</th>\n",
       "      <th>latest_salemonth</th>\n",
       "      <th>latest_saleyear</th>\n",
       "      <th>numOfAccessibilityFeatures</th>\n",
       "      <th>numOfAppliances</th>\n",
       "      <th>...</th>\n",
       "      <th>numOfElementarySchools</th>\n",
       "      <th>numOfMiddleSchools</th>\n",
       "      <th>numOfHighSchools</th>\n",
       "      <th>avgSchoolDistance</th>\n",
       "      <th>avgSchoolRating</th>\n",
       "      <th>avgSchoolSize</th>\n",
       "      <th>MedianStudentsPerTeacher</th>\n",
       "      <th>numOfBathrooms</th>\n",
       "      <th>numOfBedrooms</th>\n",
       "      <th>numOfStories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "      <td>14658.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78736.360076</td>\n",
       "      <td>30.291285</td>\n",
       "      <td>-97.777458</td>\n",
       "      <td>1.994561</td>\n",
       "      <td>1.196753</td>\n",
       "      <td>1988.247101</td>\n",
       "      <td>6.719607</td>\n",
       "      <td>2019.073407</td>\n",
       "      <td>0.012621</td>\n",
       "      <td>3.466230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044344</td>\n",
       "      <td>1.032678</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>1.824960</td>\n",
       "      <td>5.740649</td>\n",
       "      <td>1234.836062</td>\n",
       "      <td>14.836540</td>\n",
       "      <td>2.605025</td>\n",
       "      <td>3.407150</td>\n",
       "      <td>1.453882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.813433</td>\n",
       "      <td>0.098254</td>\n",
       "      <td>0.085342</td>\n",
       "      <td>0.053957</td>\n",
       "      <td>1.319437</td>\n",
       "      <td>21.428899</td>\n",
       "      <td>3.143685</td>\n",
       "      <td>0.813386</td>\n",
       "      <td>0.178817</td>\n",
       "      <td>1.891543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226084</td>\n",
       "      <td>0.249629</td>\n",
       "      <td>0.285393</td>\n",
       "      <td>1.046277</td>\n",
       "      <td>1.862691</td>\n",
       "      <td>329.232708</td>\n",
       "      <td>1.755436</td>\n",
       "      <td>0.940756</td>\n",
       "      <td>0.826083</td>\n",
       "      <td>0.518033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>78617.000000</td>\n",
       "      <td>30.085030</td>\n",
       "      <td>-98.022057</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1906.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>78727.000000</td>\n",
       "      <td>30.201381</td>\n",
       "      <td>-97.836798</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1974.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>966.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78739.000000</td>\n",
       "      <td>30.282641</td>\n",
       "      <td>-97.768124</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1277.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78749.000000</td>\n",
       "      <td>30.368274</td>\n",
       "      <td>-97.715643</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1496.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78759.000000</td>\n",
       "      <td>30.517323</td>\n",
       "      <td>-97.569504</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>1913.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            zipcode      latitude     longitude  propertyTaxRate  \\\n",
       "count  14658.000000  14658.000000  14658.000000     14658.000000   \n",
       "mean   78736.360076     30.291285    -97.777458         1.994561   \n",
       "std       18.813433      0.098254      0.085342         0.053957   \n",
       "min    78617.000000     30.085030    -98.022057         1.980000   \n",
       "25%    78727.000000     30.201381    -97.836798         1.980000   \n",
       "50%    78739.000000     30.282641    -97.768124         1.980000   \n",
       "75%    78749.000000     30.368274    -97.715643         1.980000   \n",
       "max    78759.000000     30.517323    -97.569504         2.210000   \n",
       "\n",
       "       parkingSpaces     yearBuilt  latest_salemonth  latest_saleyear  \\\n",
       "count   14658.000000  14658.000000      14658.000000     14658.000000   \n",
       "mean        1.196753   1988.247101          6.719607      2019.073407   \n",
       "std         1.319437     21.428899          3.143685         0.813386   \n",
       "min         0.000000   1906.000000          1.000000      2018.000000   \n",
       "25%         0.000000   1974.000000          4.000000      2018.000000   \n",
       "50%         1.000000   1992.000000          7.000000      2019.000000   \n",
       "75%         2.000000   2006.000000          9.000000      2020.000000   \n",
       "max        22.000000   2020.000000         12.000000      2021.000000   \n",
       "\n",
       "       numOfAccessibilityFeatures  numOfAppliances  ...  \\\n",
       "count                14658.000000     14658.000000  ...   \n",
       "mean                     0.012621         3.466230  ...   \n",
       "std                      0.178817         1.891543  ...   \n",
       "min                      0.000000         0.000000  ...   \n",
       "25%                      0.000000         2.000000  ...   \n",
       "50%                      0.000000         3.000000  ...   \n",
       "75%                      0.000000         4.000000  ...   \n",
       "max                      8.000000        11.000000  ...   \n",
       "\n",
       "       numOfElementarySchools  numOfMiddleSchools  numOfHighSchools  \\\n",
       "count            14658.000000        14658.000000      14658.000000   \n",
       "mean                 0.044344            1.032678          0.983081   \n",
       "std                  0.226084            0.249629          0.285393   \n",
       "min                  0.000000            0.000000          0.000000   \n",
       "25%                  0.000000            1.000000          1.000000   \n",
       "50%                  0.000000            1.000000          1.000000   \n",
       "75%                  0.000000            1.000000          1.000000   \n",
       "max                  2.000000            3.000000          2.000000   \n",
       "\n",
       "       avgSchoolDistance  avgSchoolRating  avgSchoolSize  \\\n",
       "count       14658.000000     14658.000000   14658.000000   \n",
       "mean            1.824960         5.740649    1234.836062   \n",
       "std             1.046277         1.862691     329.232708   \n",
       "min             0.200000         2.333333     396.000000   \n",
       "25%             1.100000         4.000000     966.000000   \n",
       "50%             1.566667         5.666667    1277.000000   \n",
       "75%             2.266667         7.000000    1496.000000   \n",
       "max             9.000000         9.500000    1913.000000   \n",
       "\n",
       "       MedianStudentsPerTeacher  numOfBathrooms  numOfBedrooms  numOfStories  \n",
       "count              14658.000000    14658.000000   14658.000000  14658.000000  \n",
       "mean                  14.836540        2.605025       3.407150      1.453882  \n",
       "std                    1.755436        0.940756       0.826083      0.518033  \n",
       "min                   10.000000        0.000000       0.000000      1.000000  \n",
       "25%                   14.000000        2.000000       3.000000      1.000000  \n",
       "50%                   15.000000        3.000000       3.000000      1.000000  \n",
       "75%                   16.000000        3.000000       4.000000      2.000000  \n",
       "max                   19.000000       27.000000      20.000000      4.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable Breakdown\n",
    "data.describe() # TODO: We could probably make this more relevant to the data by only showing the relevant columns (i.e. not the ID columns, binary columns should be shown as counts, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Determine if we need to do any further discussion of the data descriptions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Correlation Heatmap\\nnum_data = data.select_dtypes(include=[np.number])\\nplt.matshow(num_data.corr())\\nplt.xticks(range(num_data.shape[1]), num_data.columns, fontsize=14, rotation=90)\\nplt.yticks(range(num_data.shape[1]), num_data.columns, fontsize=14)\\nplt.show()\\n\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "# Correlation Heatmap\n",
    "num_data = data.select_dtypes(include=[np.number])\n",
    "plt.matshow(num_data.corr())\n",
    "plt.xticks(range(num_data.shape[1]), num_data.columns, fontsize=14, rotation=90)\n",
    "plt.yticks(range(num_data.shape[1]), num_data.columns, fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nfrom sklearn.model_selection import train_test_split\\n\\n# Split the data into a training and test set.\\ntrain, test = train_test_split(data, test_size=0.2, random_state=23)\\n\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=23)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Argue \"for\" or \"against\" splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (5 points total)\n",
    "The implementation of logistic regression must be written only from the examples given to you by the instructor. No credit will be assigned to teams that copy implementations from another source, regardless of if the code is properly cited. \n",
    "[2 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template developed by the instructor in the course. You should add the following functionality to the logistic regression classifier:\n",
    "Ability to choose optimization technique when class is instantiated: either steepest ascent, stochastic gradient ascent, and Newton's method. It is recommended to call this the \"solver\" input for the class.\n",
    "Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1 and L2 regularization). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  \n",
    "[1.5 points] Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term(s) \"C\" to achieve the best performance on your test set. Visualize the performance of the classifier versus the parameters you investigated.\n",
    "Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?\n",
    "[1.5 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time and classification performance. Discuss the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nimport numpy as np\\nclass BinaryLogisticRegressionBase:\\n    # private:\\n    def __init__(self, eta, iterations=20):\\n        self.eta = eta\\n        self.iters = iterations\\n        # internally we will store the weights as self.w_ to keep with sklearn conventions\\n    \\n    def __str__(self):\\n        return 'Base Binary Logistic Regression Object, Not Trainable'\\n    \\n    # convenience, private and static:\\n    @staticmethod\\n    def _sigmoid(theta):\\n        return 1/(1+np.exp(-theta)) \\n    \\n    @staticmethod\\n    def _add_intercept(X):\\n        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\\n    \\n    # public:\\n    def predict_proba(self, X, add_intercept=True):\\n        # add bias term if requested\\n        Xb = self._add_intercept(X) if add_intercept else X\\n        return self._sigmoid(Xb @ self.w_) # return the probability y=1\\n    \\n    def predict(self,X):\\n        return (self.predict_proba(X)>0.5) #return the actual prediction\\n    \\n    \""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_intercept(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, add_intercept=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_intercept(X) if add_intercept else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\tolbr\\AppData\\Local\\Temp\\ipykernel_11516\\1280266403.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  '''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n# inherit from base class\\nclass BinaryLogisticRegression(BinaryLogisticRegressionBase):\\n    #private:\\n    def __str__(self):\\n        if(hasattr(self,'w_')):\\n            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\\n        else:\\n            return 'Untrained Binary Logistic Regression Object'\\n        \\n    def _get_gradient(self,X,y):\\n        # programming \\\\sum_i (yi-g(xi))xi\\n        gradient = np.zeros(self.w_.shape) # set gradient to zero\\n        for (xi,yi) in zip(X,y):\\n            # the actual update inside of sum\\n            gradi = (yi - self.predict_proba(xi,add_intercept=False))*xi \\n            # reshape to be column vector and add to gradient\\n            gradient += gradi.reshape(self.w_.shape) \\n        \\n        return gradient/float(len(y))\\n       \\n    # public:\\n    def fit(self, X, y):\\n        Xb = self._add_intercept(X) # add bias term\\n        num_samples, num_features = Xb.shape\\n        \\n        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\\n        \\n        # for as many as the max iterations\\n        for _ in range(self.iters):\\n            gradient = self._get_gradient(Xb,y)\\n            self.w_ += gradient*self.eta # multiply by learning rate \\n\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "# inherit from base class\n",
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    #private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape) # set gradient to zero\n",
    "        for (xi,yi) in zip(X,y):\n",
    "            # the actual update inside of sum\n",
    "            gradi = (yi - self.predict_proba(xi,add_intercept=False))*xi \n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape) \n",
    "        \n",
    "        return gradient/float(len(y))\n",
    "       \n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_intercept(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# now lets do some vectorized coding\\nimport numpy as np\\nfrom scipy.special import expit\\n\\nclass VectorBinaryLogisticRegression(BinaryLogisticRegression):\\n    # inherit from our previous class to get same functionality\\n    @staticmethod\\n    def _sigmoid(theta):\\n        # increase stability, redefine sigmoid operation\\n        return expit(theta) #1/(1+np.exp(-theta))\\n    \\n    # but overwrite the gradient calculation\\n    def _get_gradient(self,X,y):\\n        ydiff = y-self.predict_proba(X,add_intercept=False).ravel() # get y difference\\n        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\\n        \\n        return gradient.reshape(self.w_.shape)\\n    \\n    '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# now lets do some vectorized coding\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_intercept=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        return gradient.reshape(self.w_.shape)\n",
    "    \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nclass LogisticRegression:\\n    def __init__(self, eta, iterations=20):\\n        self.eta = eta\\n        self.iters = iterations\\n        # internally we will store the weights as self.w_ to keep with sklearn conventions\\n    \\n    def __str__(self):\\n        if(hasattr(self,'w_')):\\n            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\\n        else:\\n            return 'Untrained MultiClass Logistic Regression Object'\\n        \\n    def fit(self,X,y):\\n        num_samples, num_features = X.shape\\n        self.unique_ = np.unique(y) # get each unique class value\\n        num_unique_classes = len(self.unique_)\\n        self.classifiers_ = [] # will fill this array with binary classifiers\\n        \\n        for i,yval in enumerate(self.unique_): # for each unique value\\n            y_binary = (y==yval) # create a binary problem\\n            # train the binary classifier for this class\\n            blr = VectorBinaryLogisticRegression(self.eta,\\n                                                 self.iters)\\n            blr.fit(X,y_binary)\\n            # add the trained classifier to the list\\n            self.classifiers_.append(blr)\\n            \\n        # save all the weights into one matrix, separate column for each class\\n        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\\n        \\n    def predict_proba(self,X):\\n        probs = []\\n        for blr in self.classifiers_:\\n            probs.append(blr.predict_proba(X)) # get probability for each classifier\\n        \\n        return np.hstack(probs) # make into single matrix\\n    \\n    def predict(self,X):\\n        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row\\n    \\nlr = LogisticRegression(0.1,1500)\\n\\n#  Select columns for X and y\\nX = train[['numOfBedrooms', 'numOfBathrooms', 'numOfStories']]\\n\\n\\ny = train['latestPrice']\\n\\nlr.fit(X.values,y.values)\\nprint(lr)\\n\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,\n",
    "                                                 self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row\n",
    "    \n",
    "lr = LogisticRegression(0.1,1500)\n",
    "\n",
    "#  Select columns for X and y\n",
    "X = train[['numOfBedrooms', 'numOfBathrooms', 'numOfStories']]\n",
    "\n",
    "\n",
    "y = train['latestPrice']\n",
    "\n",
    "lr.fit(X.values,y.values)\n",
    "print(lr)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nfrom sklearn.metrics import accuracy_score\\n\\n# Now we can predict the test set\\nX_test = test.drop('latestPrice', axis=1)\\nX_test = X_test[['numOfBedrooms', 'numOfBathrooms', 'numOfStories']]\\n\\ny_test = test['latestPrice']\\n\\nyhat = lr.predict(X_test.values)\\n\\nprint('Accuracy of: ',accuracy_score(y_test,yhat))\\n\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Now we can predict the test set\n",
    "X_test = test.drop('latestPrice', axis=1)\n",
    "X_test = X_test[['numOfBedrooms', 'numOfBathrooms', 'numOfStories']]\n",
    "\n",
    "y_test = test['latestPrice']\n",
    "\n",
    "yhat = lr.predict(X_test.values)\n",
    "\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment (1 points total)\n",
    "Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party implementation)? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work (1 points total)\n",
    "You have free reign to provide additional analyses. One idea: Update the code to use either \"one-versus-all\" or \"one-versus-one\" extensions of binary to multi-class classification. \n",
    "Required for 7000 level students: Implement an optimization technique for logistic regression using mean square error as your objective function (instead of maximum likelihood). Derive the gradient updates for the Hessian and use Newton's method to update the values of \"w\". Then answer, which process do you prefer: maximum likelihood OR minimum mean-squared error? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
